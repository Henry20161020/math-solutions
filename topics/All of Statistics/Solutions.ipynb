{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF++dDP0HXA1kVctGtTd8S"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Ex 2.6\n",
        "\n",
        "Let X have distribution F and density function f and let A be a subset\n",
        "of the real line. Let $I_A$(x) be the indicator function for A:\n",
        "\n",
        " \\begin{equation}\n",
        " I_A(x) =\n",
        "    \\begin{cases}\n",
        "      1 & x \\in A\\\\\n",
        "      0 & x \\notin A \\\\\n",
        "    \\end{cases}       \n",
        "\\end{equation}\n",
        "Let Y = $I_A$(X). Find an expression for the cumulative distribution of\n",
        "Y . (Hint: first find the probability mass function for Y .)\n",
        "\n",
        "Solution:\n",
        "\n",
        "There are only two values that Y can pick: 1 and 0, so we need to figure out the probability mass of P(Y=1) and P(Y=0)?\n",
        "\n",
        "We know P(Y=1) = P($X \\in A$) = $\\int_A f_F(x)$, so let's say Y's PMF is $f_Y(y)$, then $f_Y(1)$ =   $\\int_A f_F(x)$ and $f_Y(0)$ = 1 -  $\\int_A f_F(x)$\n",
        "\n",
        "Therefore, the CDF of Y is\n",
        "\\begin{equation}\n",
        " F_Y(y) =\n",
        "    \\begin{cases}\n",
        "      0 & y < 0\\\\\n",
        "      1- \\int_A f_F(x) & y \\in [0, 1) \\\\\n",
        "      1 & y >= 1\n",
        "    \\end{cases}       \n",
        "\\end{equation}\n",
        "\n"
      ],
      "metadata": {
        "id": "A3vueLY3yeXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ex 2.11\n",
        "\n",
        "Suppose we toss a coin once and let p be the probability of heads. Let\n",
        "X denote the number of heads and let Y denote the number of tails.\n",
        "(a) Prove that X and Y are dependent.\n",
        "(b) Let N ∼ Poisson(λ) and suppose we toss a coin N times. Let X and\n",
        "Y be the number of heads and tails. Show that X and Y are independent.\n",
        "\n",
        "(a)\n",
        "\n",
        "*Proof.*\n",
        "\n",
        "To prove dependency, we just need one example to show that P(x)P(y) $\\neq$ P(x,y).\n",
        "\n",
        "Here we let P(X+Y=2) = 1 and P(X+Y=i) = 0 (For any $i \\in N, i \\neq 2$)\n",
        "\n",
        "Thus P(X = 1) = 2p(1-p), P(Y = 1) = 2p(1-p) and P(X = 1, Y=1) = P(X=1) = 2p(1- p). Therefore P(x)P(y) $\\neq$ P(x,y) when p(1-p) $\\leq $ 1/4\n",
        "\n",
        "*Q.E.D.*\n",
        "\n",
        "(b)\n",
        "\n",
        "*Proof.*\n",
        "\n",
        "As N ∼ Poisson(λ) P(X+Y=N) = $\\frac{\\lambda^N}{N!} e^{\\lambda}$\n",
        "\\begin{align*}\n",
        "P(X = x, Y = y) & = P(X+Y = N) P(X = x|X+Y=N) \\\\\n",
        "& = \\frac{\\lambda^{x+y}e^{-\\lambda}}{(x + y)!} *  \\binom{x + y}{x} p^x (1-p)^y \\\\\n",
        "&= e^{-\\lambda}\\frac{\\lambda^{x+y}}{(x + y)!} *  \\frac{(x+y)!}{x!y!} p^x (1-p)^y \\\\\n",
        "& = e^{-\\lambda} \\frac{\\lambda^x}{x!} p^x \\cdot \\frac{\\lambda^y}{y!} (1 - p)^y\n",
        "\\end{align*}\n",
        "Let g(x) = $e^{-\\lambda} \\frac{\\lambda^x}{x!} p^x$ and h(y) = $\\frac{\\lambda^y}{y!} (1 - p)^y$, we know X and Y are independant from theorem 2.33.\n",
        "\n",
        "As theorem 2.33 is not proved in the text book, we prove here for completeness.\n",
        "\n",
        "2.33 Theorem. Suppose that the range of X and Y is a (possibly infinite)\n",
        "rectangle. If f(x, y) = g(x)h(y) for some functions g and h (not necessarily\n",
        "probability density functions) then X and Y are independent.\n",
        "\n",
        "Given f(x, y) = g(x)h(y)\n",
        "\n",
        "We have\n",
        "\n",
        "\\begin{align*}\n",
        "f_X(x) &= \\int f(x,y) dy\\\\\n",
        "& = g(x) \\int h(y) dy \\\\\n",
        "f_Y(y) & = \\int f(x,y) dx\\\\\n",
        "& = h(y) \\int g(x) dx\n",
        "\\end{align*}\n",
        "\n",
        "Therefore\n",
        "\n",
        "\\begin{align*}\n",
        "f_X(x) * f_Y(y) &= g(x)h(y) \\int \\int g(x)h(y) dx dy\\\\\n",
        "& = g(x)h(y) \\\\\n",
        " & = f_{X,Y}(x, y)\n",
        "\\end{align*}\n",
        "\n",
        "By theorem 2.30, we know theorem 2.33 is true.\n",
        "\n",
        "*Q.E.D.*"
      ],
      "metadata": {
        "id": "as1AZsdgUP7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ex 2.16\n",
        "Let X ∼ Poisson(λ) and Y ∼ Poisson(µ) and assume that X and Y are\n",
        "independent. Show that the distribution of X given that X + Y = n is\n",
        "Binomial(n, π) where π = λ/(λ + µ).\n",
        "Hint 1: You may use the following fact: If X ∼ Poisson(λ) and Y ∼\n",
        "Poisson(µ), and X and Y are independent, then X+Y ∼ Poisson(µ+λ).\n",
        "Hint 2: Note that {X = x, X + Y = n} = {X = x, Y = n − x}.\n",
        "\n",
        "Solution:\n",
        "\n",
        "Main Proof\n",
        "\n",
        "\\begin{align*}\n",
        " P(X=x | X+Y=n) & = \\frac{P(X=x, X+Y=n)}{P(X+Y=n)} & \\text{Conditional Prob.}\\\\\n",
        " & = \\frac{P(X=x, Y=n-x)}{P(X+Y=n)} \\\\\n",
        " & = \\frac{P(X=x) P(Y=n-x)}{P(X+Y=n)} & \\text{X, Y independent}\\\\\n",
        " & = \\frac{\\frac{\\lambda^x}{x!} e^{-\\lambda} \\frac{\\mu^y}{y!} e^{-\\mu} }{\\frac{(\\lambda+\\mu)^n}{n!} e^{-(\\lambda + \\mu)}} & \\text{Poisson PMF}\\\\\n",
        " & = \\frac{n!}{x!(n-x)!}(\\frac{\\lambda^x \\mu^{n-x}}{(\\lambda+\\mu)^n}) \\\\\n",
        " & = \\binom{n}{x}(\\frac{\\lambda}{\\lambda+\\mu})^x(\\frac{\\mu}{\\lambda+\\mu})^{n-x}\\\\\n",
        " & = \\binom{n}{x}\\pi^x(1-\\pi)^{n-x} & Binomial(n, \\pi)\n",
        "\\end{align*}\n",
        "\n",
        "Side Proof\n",
        "\n",
        "If X ∼ Poisson(λ) and Y ∼\n",
        "Poisson(µ), and X and Y are independent, then X+Y ∼ Poisson(µ+λ)\n",
        "\n",
        "This can be proved by computing the PMF of X+Y\n",
        "\n",
        "\\begin{align*}\n",
        "P(X+Y=n) &= \\Sigma_{i=0}^n P(X=i) P(Y= n-i) \\\\\n",
        "& =\\Sigma_{i=0}^n \\frac{\\lambda^i}{i!} e^{-\\lambda} \\frac{\\mu^{n-i}}{(n-i)!} e^{-\\mu}\\\\\n",
        "& = \\frac{1}{n!}\\Sigma_{i=0}^n \\frac{n!}{i!(n-i)!}  \\lambda^i \\mu^{n-i} e^{-(\\lambda+\\mu)} \\\\\n",
        "&= \\frac{(\\lambda+\\mu)^n}{n!} e^{-(\\lambda+\\mu)} & \\text{Poisson PMF}\\\\\n",
        "\\end{align*}\n",
        "\n",
        "Q.E.D."
      ],
      "metadata": {
        "id": "9kdRkROziZwQ"
      }
    }
  ]
}